This repository provides an evaluation pipeline for method name prediction using large language models (LLMs), such as GPT-3.5, CodeLlama, and StarChat. Results are benchmarked against human evaluations. Supported programming languages include Java and Python.

**requirements.txt**

```
torch==2.1.0
transformers==4.46.3
sentence-transformers==3.2.1
tqdm==4.67.1
huggingface-hub==0.33.0
openai==1.88.0
torchaudio==2.1.0
torchvision==0.16.0
```

```
**LLM_eval_code/**
â”œâ”€â”€ data/                       # Original datasets (Java and Python)
â”‚   â”œâ”€â”€ *.txt                   # Plain text format
â”‚   â””â”€â”€ *.jsonl                 # JSONL format
â”œâ”€â”€ result/                     # Model prediction results
â”‚   â”œâ”€â”€ java/                   # Evaluation results for Java
â”‚   â””â”€â”€ python/                 # Evaluation results for Python
â”œâ”€â”€ java.xlsx                   # Extracted model scores (Excel)
â”œâ”€â”€ cal_tau_rho.py             # Script for computing Kendallâ€™s Ï„ and Spearmanâ€™s Ï
â”œâ”€â”€ llm-eval.py                # Main script for evaluating method names using LLMs
â”œâ”€â”€ txt_to_jsonl.py            # Converter: .txt  to .jsonl format
```

`{model}.jsonl`: Contains raw model predictions for automated processing

`{model}-read.txt`: Human-readable formatted version of model predictions

```
â”œâ”€â”€ CSN-Premium4MNP/
â”‚   â”œâ”€â”€ code/                  # Scripts for dataset extraction and preprocessing
â”‚   â””â”€â”€ readme.md              # Dataset statistics and description
**Dataset Quality/**
â”œâ”€â”€ cal/                       # Evaluation metric implementations
â”‚   â”œâ”€â”€ java               # F1 score and SBCS computation for java
â”‚   â””â”€â”€ python                   # F1 score and SBCS computation for python
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ LLM/              # StarCoderã€StarChat-Î²ã€CodeLlama-Iã€GPT-3.5
â”‚   â””â”€â”€ PLM/                   # CodeBERTã€CodeT5
```

SentenceBERT + Cosine Similarity (SBCS) uses the following model: [**all-mpnet-base-v2**](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)

Files with `PLM` in the name are for pre-trained models such as CodeBERT and CodeT5

Files with `LLM` in the name are for large language models such as StarCoder, StarChat-Î², CodeLlama-I, and GPT-3.5

Reference implementation for CodeT5: [CodeT5](https://github.com/salesforce/CodeT5/tree/main/CodeT5)

Reference implementation for CodeBERT: [CodeBERT](https://github.com/microsoft/CodeBERT/tree/master/CodeBERT/code2nl)

```
Usage Example
# Run LLM evaluation for method name prediction
python llm-eval.py --data_file XXX/XXX/test.jsonl --model gpt-3.5
```

**Results & Data**

The results of the **Dataset Quality** evaluation and  **CSN-Premium4MN dataset** have been uploaded to:

[ğŸ“‚ CSN-Premium4MNP](https://drive.google.com/drive/folders/1HEt58MW8tvJrwLvgDQ4Cx6BW9kQuHWj2)
[ğŸ“‚ Dataset Quality evaluation](https://drive.google.com/drive/folders/12uZTmvSVSQ19dRysaANY32bgTJ3yt6OA)

